import streamlit as st
import json
import re
import requests
import zlib
import base64
from urllib.parse import urlparse
import networkx as nx
from pyvis.network import Network
import streamlit.components.v1 as components
from bs4 import BeautifulSoup
from core.database import AuditDatabase
from core.scraping import SmartScraper

# =============================================================================
# VERSION 2.5.0 - SLIDER 10-10000 + PLEIN √âCRAN FIX + SOUS-ONGLETS
# =============================================================================

# =============================================================================
# 1. STYLE & CONFIGURATION
# =============================================================================
def inject_hotaru_css():
    st.markdown("""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600&display=swap');
        html, body, [class*="css"] { font-family: 'Inter', sans-serif; color: #1a1a1a; }
        .stDeployButton, header {display:none;}
        .infra-box { padding: 15px; border-left: 3px solid #eee; margin-bottom: 10px; background: #f9f9f9; border-radius: 0 4px 4px 0; }
        .status-ok { color: #2e7d32; font-weight: 600; font-size: 0.9em; }
        .status-err { color: #c62828; font-weight: 600; font-size: 0.9em; }
        .infra-desc { font-size: 0.85em; color: #666; margin-top: 5px; line-height: 1.4; }
    </style>
    """, unsafe_allow_html=True)

# =============================================================================
# 2. FONCTIONS TECHNIQUES (SCORING & INFRA)
# =============================================================================

def check_geo_infrastructure(base_url):
    domain = base_url.rstrip('/')
    assets = {
        "robots.txt": {"url": f"{domain}/robots.txt", "desc": "Autorise GPTBot et les crawlers IA."},
        "sitemap.xml": {"url": f"{domain}/sitemap.xml", "desc": "Guide d'indexation pour les moteurs de r√©ponse."},
        "llms.txt": {"url": f"{domain}/llms.txt", "desc": "Standard 2025 pour la consommation LLM."},
        "JSON-LD": {"url": domain, "desc": "Donn√©es structur√©es (Entit√©s de marque)."}
    }
    results = {}; score = 0
    for name, data in list(assets.items())[:3]:
        try:
            r = requests.get(data['url'], timeout=3)
            found = (r.status_code == 200)
            results[name] = {"status": found, "meta": data}
            if found: score += 25
        except: results[name] = {"status": False, "meta": data}
    try:
        r = requests.get(domain, timeout=5); soup = BeautifulSoup(r.text, 'html.parser')
        has_json = bool(soup.find('script', type='application/ld+json'))
        results["JSON-LD"] = {"status": has_json, "meta": assets["JSON-LD"]}
        if has_json: score += 25
    except: results["JSON-LD"] = {"status": False, "meta": assets["JSON-LD"]}
    return results, score

def calculate_page_score(page):
    """
    Calcule le score GEO avanc√© d'une page
    Utilise le nouveau syst√®me de scoring multicrit√®re
    """
    try:
        from geo_scoring import GEOScorer
        scorer = GEOScorer()
        result = scorer.calculate_score(page)
        return result['total_score'], result['grade'], result['breakdown'], result['recommendations']
    except:
        # Fallback si geo_scoring n'existe pas
        score = 70  # Score par d√©faut
        grade = 'B'
        return score, grade, {}, []

def get_clean_label(title, url, domain):
    try:
        clean = re.split(r' [-|:|‚Ä¢] ', title)[0]
        if len(clean) < 4: clean = url.rstrip('/').split('/')[-1].replace('-', ' ').capitalize()
        return clean[:20] + ".." if len(clean) > 22 else clean
    except: return "Page"

# =============================================================================
# 3. RENDU DU GRAPHE (FIX PLEIN √âCRAN)
# =============================================================================

def render_interactive_graph(G):
    nt = Network(height="850px", width="100%", bgcolor="#ffffff", font_color="#0f172a")
    nt.from_nx(G)
    
    opts = {
        "nodes": {
            "font": {
                "face": "Inter, sans-serif",
                "size": 14,
                "strokeWidth": 3,
                "strokeColor": "#ffffff",
                "color": "#0f172a"
            },
            "borderWidth": 2,
            "borderWidthSelected": 3
        },
        "edges": {
            "color": "#cbd5e1",
            "smooth": {
                "type": "dynamic",
                "roundness": 0.2
            },
            "width": 1.5
        },
        "interaction": {
            "hover": True,
            "navigationButtons": True,
            "keyboard": True,
            "zoomView": True,
            "dragView": True,
            "dragNodes": True
        },
        "physics": {
            "forceAtlas2Based": {
                "gravitationalConstant": -100,
                "centralGravity": 0.01,
                "springLength": 200,
                "springConstant": 0.08,
                "avoidOverlap": 1
            },
            "solver": "forceAtlas2Based",
            "stabilization": {
                "enabled": True,
                "iterations": 200
            }
        }
    }

    nt.set_options(json.dumps(opts))
    path = "temp_graph.html"
    nt.save_graph(path)
    
    with open(path, "r", encoding="utf-8") as f:
        html = f.read()
    
    # FIX PLEIN √âCRAN : Applique le plein √©cran sur le container du graphe
    custom_code = """
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&display=swap');
        
        * {
            font-family: 'Inter', sans-serif !important;
        }
        
        body, html {
            font-family: 'Inter', sans-serif !important;
            color: #0f172a;
        }
        
        .vis-network canvas {
            font-family: 'Inter', sans-serif !important;
        }
        
        /* Style pour le mode plein √©cran */
        #graph-container:fullscreen {
            width: 100vw !important;
            height: 100vh !important;
        }
        
        #graph-container:-webkit-full-screen {
            width: 100vw !important;
            height: 100vh !important;
        }
        
        #graph-container:-moz-full-screen {
            width: 100vw !important;
            height: 100vh !important;
        }
        
        #graph-container:-ms-fullscreen {
            width: 100vw !important;
            height: 100vh !important;
        }
    </style>
    <script>
        // Enrober le graphe dans un container pour le plein √©cran
        var graphContainer = document.createElement('div');
        graphContainer.id = 'graph-container';
        graphContainer.style.width = '100%';
        graphContainer.style.height = '850px';
        graphContainer.style.position = 'relative';
        
        var mynetwork = document.getElementById('mynetwork');
        mynetwork.parentNode.insertBefore(graphContainer, mynetwork);
        graphContainer.appendChild(mynetwork);
        
        // Gestion des clics sur les n≈ìuds
        network.on("click", function (params) {
            if (params.nodes.length > 0) {
                var nodeId = params.nodes[0];
                if (nodeId.startsWith('http')) {
                    window.open(nodeId, '_blank');
                }
            }
        });
        
        // Bouton plein √©cran (appliqu√© sur le container)
        function toggleFullscreen() {
            var elem = document.getElementById('graph-container');
            if (!document.fullscreenElement && !document.mozFullScreenElement && 
                !document.webkitFullscreenElement && !document.msFullscreenElement) {
                if (elem.requestFullscreen) {
                    elem.requestFullscreen();
                } else if (elem.msRequestFullscreen) {
                    elem.msRequestFullscreen();
                } else if (elem.mozRequestFullScreen) {
                    elem.mozRequestFullScreen();
                } else if (elem.webkitRequestFullscreen) {
                    elem.webkitRequestFullscreen(Element.ALLOW_KEYBOARD_INPUT);
                }
            } else {
                if (document.exitFullscreen) {
                    document.exitFullscreen();
                } else if (document.msExitFullscreen) {
                    document.msExitFullscreen();
                } else if (document.mozCancelFullScreen) {
                    document.mozCancelFullScreen();
                } else if (document.webkitExitFullscreen) {
                    document.webkitExitFullscreen();
                }
            }
        }
        
        // Ajout du bouton plein √©cran
        var fullscreenBtn = document.createElement('button');
        fullscreenBtn.innerHTML = '‚õ∂ Plein √©cran';
        fullscreenBtn.style.cssText = `
            position: absolute;
            top: 20px;
            right: 20px;
            z-index: 9999;
            padding: 10px 20px;
            background: #0f172a;
            color: white;
            border: none;
            border-radius: 8px;
            font-family: 'Inter', sans-serif;
            font-size: 14px;
            font-weight: 500;
            cursor: pointer;
            box-shadow: 0 1px 2px rgba(0,0,0,0.1);
            transition: all 0.2s ease;
        `;
        fullscreenBtn.onmouseover = function() {
            this.style.background = '#1e293b';
            this.style.transform = 'translateY(-1px)';
            this.style.boxShadow = '0 4px 6px rgba(0,0,0,0.15)';
        };
        fullscreenBtn.onmouseout = function() {
            this.style.background = '#0f172a';
            this.style.transform = 'translateY(0)';
            this.style.boxShadow = '0 1px 2px rgba(0,0,0,0.1)';
        };
        fullscreenBtn.onclick = toggleFullscreen;
        graphContainer.appendChild(fullscreenBtn);
    </script>
    """
    
    components.html(html.replace("</body>", custom_code + "</body>"), height=900)

# =============================================================================
# 4. ONGLET M√âTHODOLOGIE
# =============================================================================

def render_methodologie():
    st.markdown("""
    # üéØ M√©thodologie Hotaru
    
    ## Qu'est-ce que le GEO (Generative Engine Optimization) ?
    
    Le **GEO** est l'optimisation de votre contenu pour les moteurs de r√©ponse IA comme ChatGPT, Perplexity, Claude, et Google AI Overviews. 
    Contrairement au SEO traditionnel qui vise √† appara√Ætre dans les r√©sultats de recherche, le GEO vise √† √™tre **cit√© comme source** 
    dans les r√©ponses g√©n√©r√©es par les IA.
    
    ## üîç Comment fonctionne Hotaru ?
    
    ### 1. **Analyse Infrastructure**
    Hotaru v√©rifie la pr√©sence des fichiers essentiels :
    - **robots.txt** : Autorise les crawlers IA (GPTBot, ClaudeBot, etc.)
    - **sitemap.xml** : Guide l'indexation des moteurs de r√©ponse
    - **llms.txt** : Standard 2025 pour indiquer le contenu consommable par les LLMs
    - **JSON-LD** : Donn√©es structur√©es pour l'identification des entit√©s
    
    ### 2. **Crawling Intelligent**
    - Exploration automatique de votre site (10 √† 10 000 pages)
    - Identification des patterns d'URL et clustering s√©mantique
    - Extraction des m√©tadonn√©es SEO et contenu structur√©
    
    ### 3. **Scoring GEO**
    Chaque page re√ßoit un score bas√© sur :
    - **Clart√© s√©mantique** : Structure H1-H6, paragraphes explicites
    - **Richesse contextuelle** : Meta descriptions, donn√©es structur√©es
    - **Autorit√©** : Liens internes, position dans l'architecture
    
    ### 4. **Visualisation Graph**
    - Architecture du site en graphe interactif
    - Clustering automatique par type de contenu
    - Identification des pages piliers et connexions faibles
    
    ## üé® Modes d'affichage
    
    ### Mode Standard
    Toutes les pages en gris clair, focus sur l'architecture
    
    ### Mode Sant√©
    Coloration par score GEO :
    - üü¢ **Vert** : Score > 80/100 (Excellent)
    - üü° **Jaune** : Score 60-80/100 (Bon)
    - üî¥ **Rouge** : Score < 60/100 (√Ä am√©liorer)
    
    ## üìä Interpr√©tation des r√©sultats
    
    ### Score Infrastructure < 50
    ‚ö†Ô∏è **Critique** : Votre site n'est pas optimis√© pour les crawlers IA
    - Ajoutez robots.txt avec autorisation GPTBot
    - Cr√©ez un llms.txt listant votre contenu prioritaire
    
    ### Score Infrastructure 50-75
    ‚ö° **Moyen** : Bases pr√©sentes mais optimisation incompl√®te
    - Ajoutez des donn√©es structur√©es JSON-LD
    - V√©rifiez que sitemap.xml est √† jour
    
    ### Score Infrastructure > 75
    ‚úÖ **Bon** : Infrastructure solide pour le GEO
    - Focus sur l'optimisation du contenu des pages
    
    ## üöÄ Prochaines √©tapes apr√®s l'audit
    
    1. **Prioriser les pages √† forte visibilit√©** avec score faible
    2. **Renforcer les clusters** avec peu de pages
    3. **Cr√©er des ponts** entre clusters isol√©s
    4. **Optimiser les m√©tadonn√©es** des pages strat√©giques
    
    ## üí° Ressources
    
    - [Guide Anthropic sur le GEO](https://docs.anthropic.com)
    - [Standard llms.txt](https://llmstxt.org)
    - [Schema.org pour JSON-LD](https://schema.org)
    """)

# =============================================================================
# 5. INTERFACE PRINCIPALE (AVEC SOUS-ONGLETS)
# =============================================================================

def render_audit_geo():
    inject_hotaru_css()
    db = AuditDatabase()
    user_email = st.session_state.user_email
    
    # SOUS-ONGLETS DANS AUDIT
    tab1, tab2 = st.tabs(["üîç Audit Site", "üìñ M√©thodologie"])
    
    # ============= TAB 1 : AUDIT SITE =============
    with tab1:
        # --- CHARGEMENT SIDEBAR ---
        all_audits = db.load_user_audits(user_email)
        
        # Extraction propre des noms de Workspaces
        ws_list = []
        for a in all_audits:
            ws_name = str(a.get('workspace', '')).strip()
            if ws_name and ws_name not in ws_list:
                ws_list.append(ws_name)
        
        if not ws_list: ws_list = ["Nouveau"]
        else: ws_list = sorted(ws_list) + ["+ Cr√©er Nouveau"]

        # Menu Workspace
        selected_ws = st.sidebar.selectbox("üìÇ Projets (Workspaces)", ws_list)
        
        # Filtrage historique
        filtered_audits = [a for a in all_audits if str(a.get('workspace', '')).strip() == selected_ws]

        # --- ZONE DE SCAN ---
        with st.expander("üöÄ LANCER UNE NOUVELLE ANALYSE", expanded="results" not in st.session_state):
            c1, c2 = st.columns([3, 1])
            url_in = c1.text_input("URL Racine", placeholder="https://...")
            
            default_ws = "" if selected_ws == "+ Cr√©er Nouveau" else selected_ws
            ws_in = c2.text_input("Nom du Projet", value=default_ws)
            
            # SLIDER 10 √Ä 10 000 PAGES
            limit_in = st.slider(
                "Nombre de pages √† analyser",
                min_value=10,
                max_value=10000,
                value=100,
                step=10,
                help="Choisissez entre 10 et 10 000 pages. Plus le nombre est √©lev√©, plus l'analyse sera longue."
            )
            
            if st.button("Lancer Hotaru", use_container_width=True):
                if url_in:
                    bar = st.progress(0, "Analyse infrastructure...")
                    infra, score = check_geo_infrastructure(url_in)
                    st.session_state.geo_infra = infra
                    st.session_state.geo_score = score
                    
                    scr = SmartScraper(url_in, max_urls=limit_in)
                    res, _ = scr.run_analysis(lambda m, v: bar.progress(v, m))
                    
                    st.session_state.update({
                        "results": res, 
                        "clusters": scr.get_pattern_summary(), 
                        "target_url": url_in,
                        "current_ws": ws_in if ws_in else "Non class√©"
                    })
                    st.rerun()

        # --- SECTION ARCHIVES (DANS AUDIT) ---
        if filtered_audits:
            st.divider()
            st.subheader("üìã Archives")
            
            audit_labels = {f"{a.get('nom_site') or 'Audit'} ({a.get('date')})": a for a in filtered_audits}
            
            col1, col2 = st.columns([3, 1])
            choice = col1.selectbox("Charger un audit", list(audit_labels.keys()), label_visibility="collapsed")
            
            if col2.button("Visualiser", use_container_width=True):
                r = audit_labels[choice]
                raw_data = zlib.decompress(base64.b64decode(r['data_compressed'])).decode('utf-8')
                data = json.loads(raw_data)
                st.session_state.update({
                    "results": data['results'], 
                    "clusters": data['clusters'], 
                    "target_url": r['site_url'], 
                    "geo_infra": data.get('geo_infra', {}),
                    "geo_score": data.get('geo_score', 0),
                    "current_ws": selected_ws
                })
                st.rerun()

        # --- AFFICHAGE DES R√âSULTATS ---
        if "results" in st.session_state:
            st.divider()
            
            # 1. Dashboard Infra
            g_score = st.session_state.get("geo_score", 0)
            st.markdown(f"### Score Infrastructure IA : **{g_score}/100**")
            
            if st.session_state.get("geo_infra"):
                cols = st.columns(4)
                for i, (name, d) in enumerate(st.session_state.geo_infra.items()):
                    with cols[i]:
                        status = "status-ok" if d['status'] else "status-err"
                        txt = "OK" if d['status'] else "MISSING"
                        st.markdown(f"""<div class="infra-box"><b>{name}</b><br><span class="{status}">{txt}</span><div class="infra-desc">{d['meta']['desc']}</div></div>""", unsafe_allow_html=True)

            st.divider()
            
            # 2. Commandes Graphe
            c_expert, c_save_name, c_save_btn = st.columns([1, 2, 1])
            expert_on = c_expert.toggle("Mode Sant√©", value=False)
            
            domain = urlparse(st.session_state.target_url).netloc
            s_name = c_save_name.text_input("Nom sauvegarde", value=domain.split('.')[0], label_visibility="collapsed")
            
            # 3. Sauvegarde S√©curis√©e (Trimming)
            if c_save_btn.button("Sauvegarder", use_container_width=True):
                clean_results = []
                for r in st.session_state.results:
                    clean_results.append({
                        "url": r.get("url"),
                        "title": r.get("title", "")[:100],
                        "description": r.get("description", "")[:200],
                        "h1": r.get("h1", "")[:100],
                        "response_time": r.get("response_time")
                    })
                
                payload = {
                    "results": clean_results,
                    "clusters": st.session_state.clusters,
                    "geo_infra": st.session_state.get('geo_infra', {}),
                    "geo_score": st.session_state.get('geo_score', 0)
                }
                db.save_audit(user_email, st.session_state.current_ws, st.session_state.target_url, s_name, payload)
                st.toast("‚úÖ Audit sauvegard√© avec succ√®s")

            # 4. Construction du Graphe NetworkX
            G = nx.DiGraph()
            G.add_node(
                st.session_state.target_url, 
                label=domain.upper(), 
                size=35, 
                color="#0f172a",
                font={'color': '#ffffff', 'face': 'Inter'}
            )
            
            for c in st.session_state.clusters:
                c_id = f"group_{c['name']}"
                G.add_node(
                    c_id, 
                    label=c['name'].upper(), 
                    color="#cbd5e1",
                    size=25,
                    font={'color': '#0f172a', 'face': 'Inter'}
                )
                G.add_edge(st.session_state.target_url, c_id)
                
                for p in c['samples'][:40]:
                    # Calcul du score GEO avanc√©
                    score_data = calculate_page_score(p)
                    if isinstance(score_data, tuple):
                        sc, grade, breakdown, recommendations = score_data
                    else:
                        sc = score_data
                        grade = 'N/A'
                    
                    # Couleurs grises avec variations pour le mode expert
                    if expert_on:
                        if sc >= 80:
                            col = "#94a3b8"  # Gris-bleu clair (bon)
                        elif sc >= 60:
                            col = "#64748b"  # Gris-bleu moyen (moyen)
                        else:
                            col = "#475569"  # Gris-bleu fonc√© (mauvais)
                    else:
                        col = "#e2e8f0"  # Gris tr√®s clair standard
                    
                    # Label avec note si mode expert
                    label = get_clean_label(p.get('title',''), p['url'], domain)
                    if expert_on and isinstance(score_data, tuple):
                        label = f"{label}\\n[{grade}]"
                    
                    G.add_node(
                        p['url'], 
                        label=label, 
                        size=12, 
                        color=col,
                        font={'color': '#0f172a', 'face': 'Inter'},
                        title=f"Score GEO: {sc}/100 - Grade: {grade}" if expert_on and isinstance(score_data, tuple) else ""
                    )
                    G.add_edge(c_id, p['url'])
            
            # 5. Rendu du graphe
            render_interactive_graph(G)
    
    # ============= TAB 2 : M√âTHODOLOGIE =============
    with tab2:
        render_methodologie()
