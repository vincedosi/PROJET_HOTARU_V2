# HOTARU â€” RÃ¨gle Cursor : Moteur de scraping V1 / V2

## Fichiers de rÃ©fÃ©rence

Quand tu travailles sur du scraping dans HOTARU, tu as **deux fichiers moteurs** :

- `core/scraping.py` â†’ **SmartScraper** (V1) â€” requests + Selenium
- `core/scraping_v2.py` â†’ **HotaruScraperV2** (V2) â€” Crawl4AI + Playwright async

**Ces deux fichiers sont STABLES. Ne les modifie jamais.** Toute nouvelle feature de scraping passe par un module au-dessus.

---

## Ce que fait chaque moteur

### V1 â€” `core/scraping.py` â€” `SmartScraper`
- Cascade automatique : requests â†’ requests-html â†’ Selenium headless â†’ Selenium non-headless
- SpÃ©cialisÃ© sites protÃ©gÃ©s (BMW, Cloudflare, anti-bot)
- Extraction JSON-LD double (BeautifulSoup + DOM Selenium) avec dÃ©duplication
- Synchrone, sÃ©quentiel (1 page Ã  la fois)
- ParamÃ¨tres spÃ©cifiques : `use_selenium=True`, `selenium_mode="light"`

### V2 â€” `core/scraping_v2.py` â€” `HotaruScraperV2`
- Moteur : Crawl4AI v0.8 + Playwright async
- Crawl parallÃ¨le : 10 pages simultanÃ©es par dÃ©faut (configurable)
- x5 Ã  x10 plus rapide que V1 sur sites normaux
- GÃ©nÃ¨re `markdown` et `fit_markdown` (contenu LLM-ready sans nav/footer/pub)
- Cache persistant entre sessions (`cache=True`)
- Anti-dÃ©tection natif (simulate_user, magic mode)
- Alias : `SmartScraper = HotaruScraperV2` pour import transparent

---

## Interface commune (identique V1 et V2)

```python
# Constructeur â€” mÃªmes paramÃ¨tres dans les deux classes
scraper = Scraper(
    start_urls="https://example.com",  # str ou list[str]
    max_urls=500,
    log_callback=fn,                   # optionnel
    proxy="http://ip:port",            # optionnel
    # V2 uniquement (ignorÃ©s en V1) :
    cache=True,
    concurrency=10,
)

# Lancement â€” identique V1 et V2
results, summary = scraper.run_analysis(
    progress_callback=fn,  # optionnel
    log_callback=fn,       # optionnel
)

# summary contient :
# {
#   "total_urls": int,
#   "patterns": int,
#   "stats": dict,
#   "filtered_log": list,
#   "duplicate_log": list,
# }
```

---

## Dict rÃ©sultat par page

```python
# ClÃ©s communes V1 et V2
page = {
    "url": str,
    "title": str,
    "h1": str,
    "description": str,
    "links": list[str],          # URLs internes normalisÃ©es
    "html_content": str,
    "has_structured_data": bool,
    "json_ld": list[dict],       # Blocs JSON-LD extraits et dÃ©dupliquÃ©s
    "h2_count": int,
    "lists_count": int,
    "response_time": float,
    "last_modified": str,
}

# ClÃ©s supplÃ©mentaires V2 uniquement
page["markdown"]      # Page complÃ¨te en Markdown propre
page["fit_markdown"]  # Contenu core uniquement â†’ Ã  envoyer direct au LLM
page["crawl4ai_success"] # bool
```

---

## RÃ¨gle : chaque fois qu'un module scrape un site

### Dans Streamlit â€” ajouter un toggle utilisateur

```python
# â”€â”€ Choix moteur â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
engine = st.radio(
    "âš™ï¸ Moteur de scraping",
    options=[
        "ğŸš€ V2 â€” Crawl4AI (rapide, Markdown LLM-ready)",
        "ğŸ”§ V1 â€” Selenium (robuste, sites protÃ©gÃ©s)",
    ],
    index=0,  # V2 par dÃ©faut
    horizontal=True,
    help=(
        "V2 = Playwright async, x5 plus rapide, gÃ©nÃ¨re du Markdown propre pour l'IA. "
        "V1 = cascade requestsâ†’Selenium, pour les sites qui bloquent (Cloudflare, anti-bot)."
    ),
)
use_v2 = engine.startswith("ğŸš€")

# â”€â”€ Import conditionnel â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if use_v2:
    from core.scraping_v2 import HotaruScraperV2 as Scraper
else:
    from core.scraping import SmartScraper as Scraper

# â”€â”€ Badge moteur dans les logs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
engine_label = "ğŸš€ Crawl4AI V2" if use_v2 else "ğŸ”§ Selenium V1"
st.caption(f"Moteur actif : {engine_label}")

# â”€â”€ Instanciation et crawl â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
scraper = Scraper(
    start_urls=url,
    max_urls=max_urls,
    log_callback=log_callback,
)
results, summary = scraper.run_analysis(progress_callback=progress_callback)
```

### Dans un module Python pur (audit, GEO, pipeline...)

```python
def run_module(url: str, max_urls: int = 100, engine: str = "v2"):
    """
    Args:
        engine: "v2" (dÃ©faut, Crawl4AI) ou "v1" (Selenium classique)
    """
    if engine == "v2":
        from core.scraping_v2 import HotaruScraperV2 as Scraper
    else:
        from core.scraping import SmartScraper as Scraper

    scraper = Scraper(start_urls=url, max_urls=max_urls)
    return scraper.run_analysis()
```

---

## Utiliser fit_markdown pour les analyses LLM (V2 uniquement)

```python
# AprÃ¨s un crawl V2, envoyer le contenu au LLM sans preprocessing
for page in results:
    content_for_llm = page.get("fit_markdown") or page.get("markdown") or page["html_content"]
    # â†’ content_for_llm est propre, sans nav/footer/pub
```

---

## Ce qu'il ne faut JAMAIS faire

```python
# âŒ Import fixe sans laisser le choix Ã  l'utilisateur
from core.scraping import SmartScraper  # toujours V1, jamais de choix

# âŒ Modifier scraping.py ou scraping_v2.py
# Ces fichiers sont stables â€” toute Ã©volution = nouveau fichier ou wrapper

# âŒ RÃ©Ã©crire du code de scraping inline dans un module
# Toujours passer par les classes SmartScraper / HotaruScraperV2

# âŒ Utiliser fit_markdown en V1 (clÃ© absente)
page["fit_markdown"]  # KeyError si crawl V1 â†’ utiliser .get("fit_markdown", "")
```

---

## DÃ©cision rapide

```
L'utilisateur veut scraper un site
        â”‚
        â”œâ”€ Interface Streamlit ?
        â”‚       â””â”€ st.radio V1 / V2 (dÃ©faut V2)
        â”‚
        â””â”€ Code pur / pipeline ?
                â””â”€ paramÃ¨tre engine="v2" (dÃ©faut V2)
                        â”‚
                        â”œâ”€ "v2" â†’ from core.scraping_v2 import HotaruScraperV2 as Scraper
                        â””â”€ "v1" â†’ from core.scraping import SmartScraper as Scraper
```

## Quand recommander V1 Ã  l'utilisateur

- Site avec timeout systÃ©matique en V2
- Site avec Cloudflare / anti-bot agressif
- L'utilisateur mentionne un site "protÃ©gÃ©" ou "qui bloque"
- RÃ©sultats vides avec V2 sur un site JavaScript-heavy non standard

## Quand recommander V2 Ã  l'utilisateur (dÃ©faut)

- Tout le reste
- Besoin de Markdown pour alimenter un LLM
- Crawl de plus de 50 pages (gain de vitesse significatif)
- Besoin du cache entre sessions
